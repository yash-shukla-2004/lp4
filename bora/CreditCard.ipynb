{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JLj4F2-r1bGz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU8oUcqDxr1u",
        "outputId": "05a64cac-2e07-452e-9380-25a7a8138fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A. Import Required Libraries**"
      ],
      "metadata": {
        "id": "8GcY8LQ9zqUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0HeFqxBFzmeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **B. Upload / access the dataset and Preprocessing**"
      ],
      "metadata": {
        "id": "nfTusMHKz6aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = '/content/drive/MyDrive/colab datasets/LP4_datasets/creditcard.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = df.drop(['Time', 'Class'], axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# 2. Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "INPUT_DIM = X_scaled.shape[1] # Number of features = 29 (V1 to V28 + Amount)\n",
        "\n",
        "# 3. Isolate NORMAL (non-fraudulent) transactions for training and validation\n",
        "X_normal = X_scaled[y == 0]\n",
        "X_train_normal, X_val_normal = train_test_split(\n",
        "    X_normal,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Data ready. Input dimension: {INPUT_DIM} features.\")\n",
        "print(f\"Training Autoencoder on {X_train_normal.shape[0]} normal transactions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liDCC0VNz24E",
        "outputId": "27717b83-5de5-4150-e996-85f190e5e6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ready. Input dimension: 29 features.\n",
            "Training Autoencoder on 227452 normal transactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **C. Encoder converts it into latent representation**"
      ],
      "metadata": {
        "id": "PDnA6dGi0x5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_DIM = 14     # Bottleneck size (29 / 2)\n",
        "INTERMEDIATE_DIM = 24\n",
        "\n",
        "# Define the ENCODER Network\n",
        "# Input Layer\n",
        "input_layer = Input(shape=(INPUT_DIM,), name='Input_Layer')\n",
        "\n",
        "# Compressed Layer 1\n",
        "encoded = Dense(INTERMEDIATE_DIM, activation='relu', name='Encoder_L1')(input_layer)\n",
        "\n",
        "# Latent Representation (Bottleneck)\n",
        "latent_representation = Dense(LATENT_DIM, activation='relu', name='Latent_Representation')(encoded)\n",
        "\n",
        "print(\"Encoder defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At3qa1ra0noU",
        "outputId": "bdde8c49-c62f-4ffb-bc91-3f6d283c31e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **D. Decoder Converts Back to Original Input**"
      ],
      "metadata": {
        "id": "JLj4F2-r1bGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DECODER Network\n",
        "# Decompressed Layer 1 (Symmetrical to Encoder_L1)\n",
        "decoded = Dense(INTERMEDIATE_DIM, activation='relu', name='Decoder_L1')(latent_representation)\n",
        "\n",
        "# Output Layer (Must match the Input Dimension)\n",
        "output_layer = Dense(INPUT_DIM, activation='linear', name='Output_Reconstruction')(decoded)\n",
        "\n",
        "# ---------------------------------------\n",
        "\n",
        "# Create the Full Autoencoder Model\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer, name='Anomaly_Autoencoder')\n",
        "\n",
        "print(\"Decoder and Full Autoencoder Model defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToroDC3j09qA",
        "outputId": "81a07d13-7fb0-4800-8b56-67f12d9a9d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder and Full Autoencoder Model defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **E. Compile the Model**"
      ],
      "metadata": {
        "id": "fZBQaKcY1qek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='mse', # Mean Squared Error is the metric for reconstruction quality\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model architecture\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ud7mgPvk1hnZ",
        "outputId": "191c8224-2ad3-42b3-b96d-a4e6ad866d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Anomaly_Autoencoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Anomaly_Autoencoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Encoder_L1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Latent_Representation (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m350\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Decoder_L1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Reconstruction (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │           \u001b[38;5;34m725\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Encoder_L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Latent_Representation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Decoder_L1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Reconstruction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">725</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,155\u001b[0m (8.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155</span> (8.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,155\u001b[0m (8.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155</span> (8.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **F. Train the Model**"
      ],
      "metadata": {
        "id": "gjvxA68r1z0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the input and output are identical (X_train_normal, X_train_normal), as the goal is self-reconstruction.\n",
        "\n",
        "print(\"\\nStarting Autoencoder model training...\")\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "H_auto = autoencoder.fit(\n",
        "    X_train_normal, X_train_normal,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val_normal, X_val_normal),\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Autoencoder model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MN9bJpuK17Dv",
        "outputId": "3f241fad-0102-41c7-d789-23bd8eb565b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Autoencoder model training...\n",
            "Epoch 1/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.2537 - loss: 0.6740 - val_accuracy: 0.4648 - val_loss: 0.3639\n",
            "Epoch 2/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4813 - loss: 0.3315 - val_accuracy: 0.5251 - val_loss: 0.2967\n",
            "Epoch 3/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5402 - loss: 0.2711 - val_accuracy: 0.5725 - val_loss: 0.2664\n",
            "Epoch 4/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5775 - loss: 0.2480 - val_accuracy: 0.5892 - val_loss: 0.2566\n",
            "Epoch 5/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.2282 - val_accuracy: 0.6129 - val_loss: 0.2417\n",
            "Epoch 6/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 0.2236 - val_accuracy: 0.6285 - val_loss: 0.2373\n",
            "Epoch 7/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: 0.2161 - val_accuracy: 0.6292 - val_loss: 0.2347\n",
            "Epoch 8/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 0.2105 - val_accuracy: 0.6496 - val_loss: 0.2199\n",
            "Epoch 9/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6515 - loss: 0.1987 - val_accuracy: 0.6476 - val_loss: 0.2148\n",
            "Epoch 10/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6597 - loss: 0.1910 - val_accuracy: 0.6616 - val_loss: 0.2083\n",
            "Epoch 11/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 0.1968 - val_accuracy: 0.6681 - val_loss: 0.2054\n",
            "Epoch 12/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6619 - loss: 0.1849 - val_accuracy: 0.6679 - val_loss: 0.2015\n",
            "Epoch 13/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.1874 - val_accuracy: 0.6623 - val_loss: 0.2040\n",
            "Epoch 14/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.1848 - val_accuracy: 0.6749 - val_loss: 0.1998\n",
            "Epoch 15/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6748 - loss: 0.1780 - val_accuracy: 0.6732 - val_loss: 0.1973\n",
            "Epoch 16/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.1759 - val_accuracy: 0.6687 - val_loss: 0.1958\n",
            "Epoch 17/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6737 - loss: 0.1809 - val_accuracy: 0.6750 - val_loss: 0.1968\n",
            "Epoch 18/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6732 - loss: 0.1761 - val_accuracy: 0.6757 - val_loss: 0.1950\n",
            "Epoch 19/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.1753 - val_accuracy: 0.6742 - val_loss: 0.1929\n",
            "Epoch 20/20\n",
            "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.1755 - val_accuracy: 0.6781 - val_loss: 0.1935\n",
            "Autoencoder model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **G. Calculate Reconstruction Error (Anomaly Score)**"
      ],
      "metadata": {
        "id": "fl2nkyro2lYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our **Autoencoder Model Predicts the features** (not target) given the features itself (It tries to reconstruct the input values as it is).\n",
        "\n",
        "**Error rates are low** (close to 0) when model reconstructs non-fraudulent transaction's features as it is familiar with these patterns (we train the model only on non-fraudulent data).\n",
        "\n",
        "**Fraud transactions have a larger error rate** as the model is not familiar with these patterns. (they are like 'out of syllabus' questions)."
      ],
      "metadata": {
        "id": "pToovLPsBF1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reconstructions for the entire scaled dataset (normal and fraud)\n",
        "reconstructions = autoencoder.predict(X_scaled)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for each transaction\n",
        "mse = np.mean(np.square(X_scaled - reconstructions), axis=1)\n",
        "\n",
        "# Store results in a DataFrame for easy analysis\n",
        "error_df = pd.DataFrame({\n",
        "    'Reconstruction_Error': mse,\n",
        "    'True_Class': y\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nm_FF1U2S7l",
        "outputId": "ceb3c8c6-0446-4531-abd9-94e2bc0ba146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "00bd9627",
        "outputId": "ef311fb5-eb25-42f7-cdef-4a1dd775dc68"
      },
      "source": [
        "fraud_errors = error_df[error_df['True_Class'] == 1]\n",
        "normal_errors = error_df[error_df['True_Class'] == 0]\n",
        "\n",
        "print(fraud_errors.tail())\n",
        "print(\"\\n\")\n",
        "print(normal_errors.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Reconstruction_Error  True_Class\n",
            "279863              6.202361           1\n",
            "280143              3.256271           1\n",
            "280149              3.087519           1\n",
            "281144              6.097993           1\n",
            "281674              0.024312           1\n",
            "\n",
            "\n",
            "        Reconstruction_Error  True_Class\n",
            "284802              0.444255           0\n",
            "284803              0.071799           0\n",
            "284804              0.012733           0\n",
            "284805              0.645321           0\n",
            "284806              0.067652           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **H. Evaluation**"
      ],
      "metadata": {
        "id": "DUgCbICr3RcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find a **THRESHOLD** value for all the errors to be compared with.\n",
        "\n",
        "This is the **value which is greater than 95% of the error values** of all **non-fraudulent** transactions.\n",
        "\n",
        "This also means that all other transactions with **error > THRESHOLD** will be considered **FRAUD** (including 5% normal transactions)"
      ],
      "metadata": {
        "id": "V4hVYdKkAPGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the normal (non-fraudulent) reconstruction errors\n",
        "normal_error = error_df[error_df['True_Class'] == 0].Reconstruction_Error\n",
        "\n",
        "# 1. Set Anomaly Threshold\n",
        "# Use the 95th percentile of the reconstruction error from NORMAL transactions\n",
        "THRESHOLD = np.percentile(normal_error, 95)\n",
        "print(f\"\\nCalculated Anomaly Threshold: {THRESHOLD:.6f}\")\n",
        "\n",
        "# 2. Predict anomalies for the entire dataset\n",
        "# The prediction is TRUE (1 or Fraud) if the error is above the threshold\n",
        "predicted_anomalies = error_df['Reconstruction_Error'] > THRESHOLD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJWxfzs3NMW",
        "outputId": "a4613adc-2c1d-4f82-ee2d-6f6818e776c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculated Anomaly Threshold: 0.504384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConfusion Matrix\")\n",
        "print(confusion_matrix(error_df['True_Class'], predicted_anomalies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5eaT45WD-GO",
        "outputId": "97a0479f-d0fe-4a99-e497-a6b21cdb941d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix\n",
            "[[270099  14216]\n",
            " [    75    417]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print Precision for the minority class (pos_label=1)\n",
        "precision = precision_score(error_df['True_Class'], predicted_anomalies, pos_label=1)\n",
        "print(f\"Precision: {100*precision:.2f}%\")\n",
        "\n",
        "# Calculate and print Recall for the minority class (pos_label=1)\n",
        "recall = recall_score(error_df['True_Class'], predicted_anomalies, pos_label=1)\n",
        "print(f\"Recall: {100*recall:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxFzQ_MPDAyi",
        "outputId": "c9f05257-d2d7-47e2-e7be-79b9dc192e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 2.85%\n",
            "Recall: 84.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the **main evaluation metric is Recall** and not Precision.\n",
        "\n",
        "High Recall indicates that higher number of Fraud transactions have been correctly flagged, which is the main goal."
      ],
      "metadata": {
        "id": "F5KHtBHZHB1v"
      }
    }
  ]
}