{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWLfmtvF7G-j",
        "outputId": "b43cc80e-c677-4c72-8d73-688d078f81a2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DCaeDsy7CLV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# a) Import required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOU3c0lD7PZR",
        "outputId": "4c6022b0-97a7-4d2f-de17-538c0e09ac67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Pre-trained VGG16 model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 1: Load the Pre-trained CNN Model (VGG16 without top)\n",
        "# ==========================================================\n",
        "base_model = VGG16(weights='/content/drive/MyDrive/colab datasets/LP4_datasets/vgg16_weights.h5',\n",
        "                   include_top=False,\n",
        "                   input_shape=(224, 224, 3))\n",
        "\n",
        "print(\"âœ… Pre-trained VGG16 model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_x21U027mCb",
        "outputId": "7b103bce-a1f0-400b-e10c-7e090eb41fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Base layers frozen.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 2: Freeze lower convolutional layers\n",
        "# ==========================================================\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"âœ… Base layers frozen.\")\n",
        "\n",
        "# ==========================================================\n",
        "# Step 3: Add custom classifier (fully connected layers)\n",
        "# ==========================================================\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoTADS2U7jSq"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# Step 4: Compile the model\n",
        "# ==========================================================\n",
        "model.compile(optimizer=Adam(learning_rate=0.1),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNlLtLFY7xIv",
        "outputId": "2c571637-533e-4428-fbdc-ce38dc53cebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 446 images belonging to 10 classes.\n",
            "Found 105 images belonging to 10 classes.\n",
            "âœ… Dataset loaded successfully.\n",
            "Number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 5: Prepare the dataset (images in subfolders)\n",
        "# ==========================================================\n",
        "data_dir = \"/content/drive/MyDrive/IT Notes/SEM_7_NOTES/LP-4/objects\"  # your dataset folder\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 80% training, 20% validation\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(\"âœ… Dataset loaded successfully.\")\n",
        "\n",
        "\n",
        "print(\"Number of classes:\", train_generator.num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU9cElVk70mL",
        "outputId": "4ea3145f-5216-4505-9be7-22b0577689ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 29s/step - accuracy: 0.0940 - loss: 1188.5477 - val_accuracy: 0.0952 - val_loss: 8.2001\n",
            "Epoch 2/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 27s/step - accuracy: 0.1120 - loss: 22.5461 - val_accuracy: 0.1524 - val_loss: 2.2389\n",
            "Epoch 3/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 26s/step - accuracy: 0.1582 - loss: 11.0357 - val_accuracy: 0.1619 - val_loss: 2.2499\n",
            "Epoch 4/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 25s/step - accuracy: 0.1640 - loss: 8.6762 - val_accuracy: 0.1524 - val_loss: 2.2682\n",
            "Epoch 5/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 25s/step - accuracy: 0.1681 - loss: 2.2581 - val_accuracy: 0.1524 - val_loss: 2.2642\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 6: Train the classifier layers\n",
        "# ==========================================================\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFig3e7nH6dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a16a0e-55cf-41bc-ba8c-a124c8129734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ Fine-tuning top layers...\n",
            "Epoch 1/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 30s/step - accuracy: 0.1335 - loss: 2.2795 - val_accuracy: 0.1524 - val_loss: 2.2642\n",
            "Epoch 2/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 31s/step - accuracy: 0.1686 - loss: 2.2629 - val_accuracy: 0.1524 - val_loss: 2.2642\n",
            "Epoch 3/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 30s/step - accuracy: 0.1628 - loss: 2.2503 - val_accuracy: 0.1524 - val_loss: 2.2642\n",
            "Epoch 4/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 31s/step - accuracy: 0.1592 - loss: 9.0043 - val_accuracy: 0.1524 - val_loss: 2.2642\n",
            "Epoch 5/5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 30s/step - accuracy: 0.1471 - loss: 34.7250 - val_accuracy: 0.1524 - val_loss: 2.2642\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 7: Fine-tune (unfreeze top layers)\n",
        "# ==========================================================\n",
        "# Unfreeze last 4 convolutional layers\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Re-compile with smaller learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"ğŸ”„ Fine-tuning top layers...\")\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBiPkQUJ73x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c56f00-98e8-448f-c509-3669614898a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 15s/step - accuracy: 0.1266 - loss: 2.2781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Final Validation Accuracy: 15.24%\n",
            "âœ… Model saved successfully as vgg16_transfer_learning_final.h5\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Step 8: Evaluate and Save the model\n",
        "# ==========================================================\n",
        "loss, acc = model.evaluate(val_generator)\n",
        "print(f\"\\nâœ… Final Validation Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "model.save(\"vgg16_transfer_learning_final.h5\")\n",
        "print(\"âœ… Model saved successfully as vgg16_transfer_learning_final.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}