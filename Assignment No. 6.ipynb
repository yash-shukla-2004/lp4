{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c2e651-8075-41a1-b996-30bca14f1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d03af-e7eb-406f-b9dc-9dad72072a3f",
   "metadata": {},
   "source": [
    "#### Pre processing img data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae4a153-6f00-4265-add9-35904409dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40079 images belonging to 10 classes.\n",
      "Found 9916 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"cifar-10-img/train\"\n",
    "test_dir = \"cifar-10-img/test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")\n",
    "\n",
    "# here batch_size is the number of images in each batch\n",
    "train_batch_size = 5000\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_batch_size = 1000\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=test_batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609c200-c5fc-4067-b3b3-bd8b7226e27d",
   "metadata": {},
   "source": [
    "#### Selecting only first batch with 5000 images as train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4369f09-67f5-4f91-a6f2-971ed179dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train =  train_generator[0]\n",
    "x_test, y_test = test_generator[0]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db56097-894f-44a2-8b54-8241acd0dea9",
   "metadata": {},
   "source": [
    "#### a. Load in a pre-trained CNN model trained on a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e80ede0-af89-4fd0-b431-191d5f6401d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 without top layers\n",
    "weights_path = \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc0b6a-99ae-4197-aae2-288d54241ce4",
   "metadata": {},
   "source": [
    "#### b. Freeze parameters (weights) in model’s lower convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64173b6-f973-416d-95a5-bfb158f9aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324ff8f4-4cb4-451e-a72b-3f35ee41f600",
   "metadata": {},
   "source": [
    "#### c. Add custom classifier with several layers of trainable parameters to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44e9909-36b2-48cb-8470-1e6648a229a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0aac27-8b92-4f9d-a43a-af5633d440b8",
   "metadata": {},
   "source": [
    "#### d. Train classifier layers on training data available for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce936f9-8497-4be8-877b-63d8f7c27885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.2086 - loss: 2.1383 - val_accuracy: 0.4180 - val_loss: 1.6459\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - accuracy: 0.4243 - loss: 1.6413 - val_accuracy: 0.4610 - val_loss: 1.4950\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.4928 - loss: 1.4554 - val_accuracy: 0.4700 - val_loss: 1.4558\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 157ms/step - accuracy: 0.5292 - loss: 1.3502 - val_accuracy: 0.5070 - val_loss: 1.3964\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - accuracy: 0.5480 - loss: 1.2887 - val_accuracy: 0.4990 - val_loss: 1.3898\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.5564 - loss: 1.2528 - val_accuracy: 0.5220 - val_loss: 1.3672\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 174ms/step - accuracy: 0.5997 - loss: 1.1701 - val_accuracy: 0.5130 - val_loss: 1.3799\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 151ms/step - accuracy: 0.5987 - loss: 1.1329 - val_accuracy: 0.5360 - val_loss: 1.3580\n",
      "Epoch 9/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 149ms/step - accuracy: 0.6257 - loss: 1.0722 - val_accuracy: 0.5190 - val_loss: 1.3782\n",
      "Epoch 10/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - accuracy: 0.6416 - loss: 1.0212 - val_accuracy: 0.5270 - val_loss: 1.3473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ae08a6e4b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fc40f-4c47-462f-8965-9026bdb98edb",
   "metadata": {},
   "source": [
    "#### e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6efc6-3209-4586-8947-385a0120f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 403ms/step - accuracy: 0.1888 - loss: 2.1516 - val_accuracy: 0.3870 - val_loss: 1.6010\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 455ms/step - accuracy: 0.4625 - loss: 1.4330 - val_accuracy: 0.5320 - val_loss: 1.2923\n",
      "Epoch 3/10\n",
      "\u001b[1m50/79\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 428ms/step - accuracy: 0.6021 - loss: 1.1116"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))\n",
    "# freeze all layers first\n",
    "for layer in base_model.layers:\n",
    "   layer.trainable = False\n",
    "# unfreeze last 4 layers of base model\n",
    "for layer in base_model.layers[len(base_model.layers) - 4:]:\n",
    "   layer.trainable = True\n",
    "# fine-tuning hyper parameters\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# training fine tuned model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc035871-ca9a-4c0e-9204-d999e14c53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predicted_value = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637d2e8-05ea-4e4d-a38b-b2c1ca6c76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4825f5-8e54-47a9-ab3b-57e55c9d11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 890\n",
    "plt.imshow(x_test[n])\n",
    "print(\"Preditcted: \",labels[np.argmax(predicted_value[n])])\n",
    "print(\"Actual: \", labels[np.argmax(y_test[n])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
